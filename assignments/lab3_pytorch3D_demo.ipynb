{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+plgpQ68fQsQVFFBQckiX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallpaz/3dsystems23/blob/main/assignments/lab3_pytorch3D_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlemH8x2kMUW"
      },
      "source": [
        "# 3D Graphics Systems | AI Graphics - Theory and Practice | IMPA 2023\n",
        "### Instructor: Luiz Velho\n",
        "### TA: Hallison Paz\n",
        "### Course info: https://lvelho.impa.br/i3d23/\n",
        "\n",
        "## Lab Class #2 - A demo of some functionalities of PyTorch3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su6N9qCvsNRN"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith((\"1.13.\", \"2.0.\")) and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgKLKDssk4lp"
      },
      "source": [
        "## Data Structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwOeD42hsqN-"
      },
      "source": [
        "from pytorch3d.structures import Meshes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9K0w2LZtzVy"
      },
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_BYq8QI1UvA"
      },
      "source": [
        "!wget -P . https://raw.githubusercontent.com/hallpaz/3dsystems20/master/extensions_utils/cube.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N17f8dtstYhJ"
      },
      "source": [
        "# Vertex coordinates for a level 0 cube.\n",
        "_cube_verts0 = [\n",
        "    [-0.50, 0.50, 0.50],\n",
        "    [-0.50, -0.50, 0.50],\n",
        "    [0.50, -0.50, 0.50],\n",
        "    [0.50, 0.50, 0.50],\n",
        "\n",
        "    [-0.50, 0.50, -0.50],\n",
        "    [-0.50, -0.50, -0.50],\n",
        "    [0.50, -0.50, -0.50],\n",
        "    [0.50, 0.50, -0.50]\n",
        "]\n",
        "\n",
        "\n",
        "# Faces for level 0 cube\n",
        "_cube_faces0 = [\n",
        "    [0, 1, 2],\n",
        "    [2, 3, 0],\n",
        "    [7, 6, 5],\n",
        "    [4, 7, 5],\n",
        "    [6, 3, 2],\n",
        "    [3, 6, 7],\n",
        "    [4, 5, 0],\n",
        "    [0, 5, 1],\n",
        "    [3, 4, 0],\n",
        "    [4, 3, 7],\n",
        "    [2, 1, 5],\n",
        "    [5, 6, 2],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGO_5eFdzqZw"
      },
      "source": [
        "from cube import cube"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUAmdlQXz2I4"
      },
      "source": [
        "refinedcube = cube(1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvJE3EXGs0SI"
      },
      "source": [
        "verts_list = [torch.tensor(_cube_verts0, device=device), refinedcube.verts_list()[0]]\n",
        "faces_list = [torch.tensor(_cube_faces0, dtype=torch.int64, device=device), refinedcube.faces_list()[0]]\n",
        "\n",
        "mesh_batch = Meshes(verts=verts_list, faces=faces_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc8E6hsKub0r"
      },
      "source": [
        "## Packed and Padded Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxkYo-2QucJn"
      },
      "source": [
        "# packed representation\n",
        "verts_packed = mesh_batch.verts_packed()\n",
        "\n",
        "# auxiliary tensors\n",
        "mesh_to_vert_idx = mesh_batch.mesh_to_verts_packed_first_idx()\n",
        "vert_to_mesh_idx = mesh_batch.verts_packed_to_mesh_idx()\n",
        "\n",
        "# edges\n",
        "edges = mesh_batch.edges_packed()\n",
        "\n",
        "# face normals\n",
        "face_normals = mesh_batch.faces_normals_packed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbW2CzveycNV"
      },
      "source": [
        "verts_packed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Ip61bSymPp"
      },
      "source": [
        "mesh_batch.verts_padded()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PqchT7-ujIS"
      },
      "source": [
        "## Input / Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jW2lecO1Gxb"
      },
      "source": [
        "!mkdir -p data\n",
        "!wget -P data https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow.obj\n",
        "!wget -P data https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow.mtl\n",
        "!wget -P data https://dl.fbaipublicfiles.com/pytorch3d/data/cow_mesh/cow_texture.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lkYymVnuhfp"
      },
      "source": [
        "from pytorch3d.io import load_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63sgoCwAuiHG"
      },
      "source": [
        "obj_file = \"data/cow.obj\"\n",
        "verts, faces, aux = load_obj(obj_file)\n",
        "\n",
        "faces = faces.verts_idx\n",
        "normals = aux.normals\n",
        "textures = aux.verts_uvs\n",
        "materials = aux.material_colors\n",
        "tex_maps = aux.texture_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCU7cosX1-oe"
      },
      "source": [
        "tex_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRgsokFO2S1r"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pytorch3d.renderer import Textures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KT3sU9X2Yom"
      },
      "source": [
        "plt.imshow(tex_maps['material_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADvAzZCAurrz"
      },
      "source": [
        "# 3D Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlS5FCuMusSy"
      },
      "source": [
        "from pytorch3d.transforms import Transform3d, Rotate, Translate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bTRvhvuxD6"
      },
      "source": [
        "# example 1\n",
        "T = Translate(torch.FloatTensor([[1.0, 2.0, 3.0]]), device=device)\n",
        "R = Rotate(torch.FloatTensor([[0, 1, 0], [0, 0, 1], [1, 0, 0]]), device=device)\n",
        "RT = Transform3d(device=device).compose(R, T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRJ8x-V49qjX"
      },
      "source": [
        "RT.get_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YquyzbfEu2TY"
      },
      "source": [
        "# applying Transform\n",
        "verts_transformed = RT.transform_points(mesh_batch.verts_packed())\n",
        "verts_transformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quww6Vt8vGLD"
      },
      "source": [
        "# Renderer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pz3Zq40vTZj"
      },
      "source": [
        "from pytorch3d.renderer import (\n",
        "    OpenGLPerspectiveCameras, look_at_view_transform,\n",
        "    RasterizationSettings, BlendParams,\n",
        "    MeshRenderer, MeshRasterizer, HardPhongShader,\n",
        "    Textures\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbsodBqUu5PA"
      },
      "source": [
        "R, T = look_at_view_transform(2.7, 10, 20)\n",
        "cameras = OpenGLPerspectiveCameras(device=device, R=R, T=T)\n",
        "raster_settings = RasterizationSettings(\n",
        "    image_size=512,\n",
        "    blur_radius=0.0,\n",
        "    faces_per_pixel=1, # sets the value of K\n",
        ")\n",
        "\n",
        "renderer = MeshRenderer(\n",
        "    rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
        "    shader=HardPhongShader(device=device, cameras=cameras)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgzvvZqQ_5DX"
      },
      "source": [
        "# Creating a texture for the mesh\n",
        "white_tex = torch.ones_like(mesh_batch.verts_padded())\n",
        "textures = Textures(verts_rgb=white_tex.to(device))\n",
        "mesh_batch.textures = textures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLA4K9_b_TJ0"
      },
      "source": [
        "images = renderer(mesh_batch, cameras=cameras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jux5okrAy2g"
      },
      "source": [
        "def plot_side_by_side(images):\n",
        "  n = images.shape[0]\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  for i in range(n):\n",
        "    fig.add_subplot(1, n, i+1)\n",
        "    plt.imshow(images[i, ..., :3].cpu().numpy())\n",
        "    # plt.grid(\"off\");\n",
        "    # plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cymbG-kzl1to"
      },
      "source": [
        "plot_side_by_side(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG18uXGfoAl_"
      },
      "source": [
        "from math import radians, cos, sin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpHTpbHFBNzk"
      },
      "source": [
        "cos45 = cos(radians(45))\n",
        "sin45 = sin(radians(45))\n",
        "# applying a transform to the first mesh\n",
        "SR = Transform3d(device=device).scale(1.0, 1.5, 1.0).rotate(\n",
        "      R=torch.tensor([[cos45, -sin45, 0.0], [sin45, cos45, 0.0], [0.0, 0.0, 1.0]])\n",
        "    )\n",
        "verts0 = mesh_batch.verts_list()[0]\n",
        "verts0 = SR.transform_points(verts0)\n",
        "verts1 = mesh_batch.verts_list()[1]\n",
        "mesh_batch2 = Meshes(verts=[verts0, verts1], faces=mesh_batch.faces_list(), textures=mesh_batch.textures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKBrPN7FmI5n"
      },
      "source": [
        "plot_side_by_side(renderer(mesh_batch2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "1. Change the texture of the mesh_batch so that each of the cubes is colored differently.\n",
        "\n",
        "2. Experiment different transforms and compositions in terms of rotation, translation and scaling."
      ],
      "metadata": {
        "id": "DeLykZx4Wk6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below this cell"
      ],
      "metadata": {
        "id": "A01RbUsFVJoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implicit Modeling and *cubify*"
      ],
      "metadata": {
        "id": "cTYq_fwz88ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.ops import cubify\n",
        "from pytorch3d.io import IO"
      ],
      "metadata": {
        "id": "cvzZGtki9FrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = [-1, 1]\n",
        "y_axis = [-1, 1]\n",
        "z_axis = [-1, 1]\n",
        "depth = 64\n",
        "height = 64\n",
        "width = 64\n",
        "\n",
        "volume = torch.zeros([depth, height, width])"
      ],
      "metadata": {
        "id": "kmOdrjPI9zFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some examples of surfaces defined implicitly\n",
        "sphere = lambda x: x[0]**2 + x[1]**2 + x[2]**2 - 0.8**2\n",
        "torus = lambda x: (0.6 - torch.sqrt(x[0]**2 + x[1]**2))**2 + x[2]**2 - 0.3**2"
      ],
      "metadata": {
        "id": "2NC9bXw4-KbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "function = sphere\n",
        "for d in range(depth):\n",
        "  for h in range(height):\n",
        "    for w in range(width):\n",
        "      x = (d - depth/2) / (depth/2)\n",
        "      y = (h - height/2) / (height/2)\n",
        "      z = (w - width/2) / (width/2)\n",
        "      point = torch.tensor([x, y, z])\n",
        "      if function(point) <= 0:\n",
        "        volume[d, h, w] = 1.0"
      ],
      "metadata": {
        "id": "KgjmSRxuJOYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cubified = cubify(volume.unsqueeze(0), 0.7)"
      ],
      "metadata": {
        "id": "DgCZoL3nAvw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IO().save_mesh(cubified, \"cubified_mesh.obj\")"
      ],
      "metadata": {
        "id": "hjn21bHIDr3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "3. Can you substitute the ````for```` loops for vectorized operations using Numpy or PyTorch functions?\n",
        "\n",
        "4. Can you make the cubified sphere look \"rounded\"? \n",
        "\n",
        "5. Train a neural network to learn a occupancy function for a 3D surface. Use the ```cubify``` method to generate a mesh, and visualize it."
      ],
      "metadata": {
        "id": "_0bH_lilImFF"
      }
    }
  ]
}